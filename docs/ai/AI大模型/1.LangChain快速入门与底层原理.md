**示例代码**

[langchain-base.ppt](https://www.yuque.com/attachments/yuque/0/2025/ppt/1387387/1745159935229-4d3732de-e115-4fac-a403-44ee5046a31c.ppt)

_<font style="color:#DF2A3F;">注：将ppt后缀名改为zip后解压</font>_

python版本：3.12.4

## <font style="color:rgb(51, 51, 51);">简介</font>
<font style="color:rgb(51, 51, 51);">LangChain 是一个开源的 Python AI 应用开发框架, 它提供了构建基于大模型的 AI 应用所需的模块和工具。通过 LangChain, 开发者可以轻松地与大型语言模型 (LLM) 集成, 完成文本生成、问答、翻译、对话等任务。LangChain 降低了 AI 应用开发的门槛, 让任何人都可以基于 LLM 构建属于自己的创意应用。</font>

**<font style="color:rgb(51, 51, 51);">LangChain 特性：</font>**

+ **<font style="color:rgb(51, 51, 51);">LLM 和提示（Prompt）</font>**<font style="color:rgb(51, 51, 51);">：LangChain 对所有 LLM 大模型进行了 API 抽象，统一了大模型访问 API，同时提供了 Prompt 提示模板管理机制。</font>
+ **<font style="color:rgb(51, 51, 51);">链 (Chain)</font>**<font style="color:rgb(51, 51, 51);">：Langchain 对一些常见的场景封装了一些现成的模块，例如：基于上下文信息的问答系统，自然语言生成 SQL 查询等等，因为实现这些任务的过程就像工作流一样，一步一步的执行，所以叫链 (chain)。</font>
+ **<font style="color:rgb(51, 51, 51);">LCEL</font>**<font style="color:rgb(51, 51, 51);">：LangChain Expression Language (LCEL)， langchain 新版本的核心特性，用于解决工作流编排问题，通过 LCEL 表达式，我们可以灵活的自定义 AI 任务处理流程，也就是灵活自定义</font>_<font style="color:rgb(51, 51, 51);">链 (Chain)</font>_<font style="color:rgb(51, 51, 51);">。</font>
+ **<font style="color:rgb(51, 51, 51);">数据增强生成 (RAG)</font>**<font style="color:rgb(51, 51, 51);">：因为大模型 (LLM) 不了解新的信息，无法回答新的问题，所以我们可以将新的信息导入到 LLM，用于增强 LLM 生成内容的质量，这种模式叫做 RAG 模式(Retrieval Augmented Generation)。</font>
+ **<font style="color:rgb(51, 51, 51);">Agents</font>**<font style="color:rgb(51, 51, 51);">：是一种基于大模型（LLM）的应用设计模式，利用 LLM 的自然语言理解和推理能力（LLM 作为大脑)），根据用户的需求自动调用外部系统、设备共同去完成任务，例如：用户输入 “明天请假一天”， 大模型（LLM）自动调用请假系统，发起一个请假申请。</font>
+ **<font style="color:rgb(51, 51, 51);">模型记忆（memory）</font>**<font style="color:rgb(51, 51, 51);">：让大模型 (llm) 记住之前的对话内容，这种能力成为模型记忆（memory）。</font>

## <font style="color:rgb(51, 51, 51);">LangChain 框架组成</font>
![image-1753858752963](http://img.minalz.cn/typora/image-1753858752963.svg)

<font style="color:rgb(51, 51, 51);">LangChain 框架由几个部分组成，包括：</font>

+ **<font style="color:rgb(51, 51, 51);">LangChain 库</font>**<font style="color:rgb(51, 51, 51);">：Python 和 JavaScript 库。包含接口和集成多种组件的运行时基础，以及现成的链和代理的实现。</font>
+ **<font style="color:rgb(51, 51, 51);">LangChain 模板</font>**<font style="color:rgb(51, 51, 51);">：Langchain 官方提供的一些 AI 任务模板。</font>
+ **<font style="color:rgb(51, 51, 51);">LangServe</font>**<font style="color:rgb(51, 51, 51);">：基于 FastAPI 可以将 Langchain 定义的链 (Chain)，发布成为 REST API。</font>
+ **<font style="color:rgb(51, 51, 51);">LangSmith</font>**<font style="color:rgb(51, 51, 51);">：开发平台，是个云服务，支持 Langchain debug、任务监控。</font>

## <font style="color:rgb(51, 51, 51);">LangChain 库 (Libraries)</font>
<font style="color:rgb(51, 51, 51);">LangChain 库本身由几个不同的包组成。</font>

+ `**<font style="color:rgb(51, 51, 51);background-color:rgb(243, 244, 244);">langchain-core</font>**`<font style="color:rgb(51, 51, 51);">：基础抽象和 LangChain 表达语言。</font>
+ `**<font style="color:rgb(51, 51, 51);background-color:rgb(243, 244, 244);">langchain-community</font>**`<font style="color:rgb(51, 51, 51);">：第三方集成，主要包括 langchain 集成的第三方组件。</font>
+ `**<font style="color:rgb(51, 51, 51);background-color:rgb(243, 244, 244);">langchain</font>**`<font style="color:rgb(51, 51, 51);">：主要包括链 (chain)、代理(agent) 和检索策略。</font>

## <font style="color:rgb(51, 51, 51);">langchain 任务处理流程</font>
![image-1753858753082](http://img.minalz.cn/typora/image-1753858753082.jpeg)

<font style="color:rgb(51, 51, 51);">如上图，langChain 提供一套提示词模板 (prompt template) 管理工具，负责处理提示词，然后传递给大模型处理，最后处理大模型返回的结果，</font>

<font style="color:rgb(51, 51, 51);">LangChain 对大模型的封装主要包括 LLM 和 Chat Model 两种类型。</font>

+ <font style="color:rgb(51, 51, 51);">LLM - 问答模型，模型接收一个文本输入，然后返回一个文本结果。</font>
+ <font style="color:rgb(51, 51, 51);">Chat Model - 对话模型，接收一组对话消息，然后返回对话消息，类似聊天消息一样。</font>

## <font style="color:rgb(51, 51, 51);">核心概念</font>
### <font style="color:rgb(51, 51, 51);">1. LLMs</font>
<font style="color:rgb(51, 51, 51);">LangChain 封装的基础模型，模型接收一个文本输入，然后返回一个文本结果。</font>

### <font style="color:rgb(51, 51, 51);">2. Chat Models</font>
<font style="color:rgb(51, 51, 51);">聊天模型（或者成为对话模型），与 LLMs 不同，这些模型专为对话场景而设计。模型可以接收一组对话消息，然后返回对话消息，类似聊天消息一样。</font>

### <font style="color:rgb(51, 51, 51);">3. 消息（Message）</font>
<font style="color:rgb(51, 51, 51);">指的是聊天模型（Chat Models）的消息内容，消息类型包括包括 HumanMessage、AIMessage、SystemMessage、FunctionMessage 和 ToolMessage 等多种类型的消息。</font>

### <font style="color:rgb(51, 51, 51);">4. 提示 (prompts)</font>
<font style="color:rgb(51, 51, 51);">LangChain 封装了一组专门用于提示词 (prompts) 管理的工具类，方便我们格式化提示词 (prompts) 内容。</font>

### <font style="color:rgb(51, 51, 51);">5. 输出解析器 (Output Parsers)</font>
<font style="color:rgb(51, 51, 51);">如上图介绍，Langchain 接受大模型 (llm) 返回的文本内容之后，可以使用专门的输出解析器对文本内容进行格式化，例如解析 json、或者将 llm 输出的内容转成 python 对象。</font>

### <font style="color:rgb(51, 51, 51);">5. Retrievers</font>
<font style="color:rgb(51, 51, 51);">为方便我们将私有数据导入到大模型（LLM）, 提高模型回答问题的质量，LangChain 封装了检索框架 (Retrievers)，方便我们加载文档数据、切割文档数据、存储和检索文档数据。</font>

### <font style="color:rgb(51, 51, 51);">6. 向量存储 (Vector stores)</font>
<font style="color:rgb(51, 51, 51);">为支持私有数据的语义相似搜索，langchain 支持多种向量数据库。</font>

### <font style="color:rgb(51, 51, 51);">7. Agents</font>
<font style="color:rgb(51, 51, 51);">智能体 (Agents)，通常指的是以大模型（LLM）作为决策引擎，根据用户输入的任务，自动调用外部系统、硬件设备共同完成用户的任务，是一种以大模型（LLM）为核心的应用设计模式。</font>

## <font style="color:rgb(51, 51, 51);">应用场景</font>
+ <font style="color:rgb(51, 51, 51);">对话机器人: 构建智能的对话助手、客服机器人、聊天机器人等。</font>
+ <font style="color:rgb(51, 51, 51);">知识库问答: 结合知识图谱, 进行开放域问题的问答服务。</font>
+ <font style="color:rgb(51, 51, 51);">智能写作: 如文章写作、创意写作、文本摘要等</font>

## <font style="color:rgb(0, 0, 0);">快速入门</font>
### <font style="color:rgb(0, 0, 0);">安装LangChain</font>
<font style="color:rgb(0, 0, 0);">要安装LangChain，可以使用Pip和Conda进行安装。以下是安装LangChain的步骤：</font>

<font style="color:rgb(0, 0, 0);">使用Pip:</font>

```bash
pip install langchain
```

### <font style="color:rgb(0, 0, 0);">初始化模型</font>
<font style="color:rgb(0, 0, 0);">在使用LangChain之前，需要导入LangChain x OpenAI集成包，并设置API密钥作为环境变量或直接传递给OpenAI LLM类。</font>

<font style="color:rgb(0, 0, 0);">首先，获取OpenAI的API密钥，可以通过创建账户并访问</font>[<font style="color:rgb(0, 0, 0);">此链接</font>](https://platform.openai.com/account/api-keys)<font style="color:rgb(0, 0, 0);">来获取。然后，可以将API密钥设置为环境变量，方法如下：</font>

```bash
export OPENAI_API_KEY="YOUR_API_KEY"
```

<font style="color:rgb(0, 0, 0);">接下来，初始化模型：</font>

```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI()
```



### <font style="color:rgb(0, 0, 0);">使用LLM</font>
<font style="color:rgb(0, 0, 0);">使用LLM来回答问题非常简单。可以直接调用LLM的</font>`<font style="color:rgb(0, 0, 0);">invoke</font>`<font style="color:rgb(0, 0, 0);">方法，并传入问题作为参数。此外，还可以通过提示模板(prompt template)生成提示词，用于向模型(LLM)发送指令。</font>

<font style="color:rgb(0, 0, 0);">下面演示了如何构建一个简单的LLM链(chains)：</font>

```python
from langchain_core.prompts import ChatPromptTemplate

# 创建一个提示模板(prompt template)
# 这里以对话模型的消息格式为例子，不熟悉openai对话模型消息格式，建议先学习OpenAI的API教程
# 下面消息模板，定义两条消息，system消息告诉模型扮演什么角色，user消息代表用户输入的问题，这里用了一个占位符{input} 代表接受一个模版参数input。
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是世界级的技术专家"),
    ("user", "{input}")
])

# 基于LCEL 表达式构建LLM链，lcel语法类似linux的pipeline语法，从左到右按顺序执行
# 下面编排了一个简单的工作流，首先执行prompt完成提示词模板(prompt template)格式化处理， 然后将格式化后的prompt传递给llm模型执行，最终返回llm执行结果。
chain = prompt | llm

# 调用LLM链并设置模板参数input,  invoke会把调用参数传递给prompt提示模板，开始chain定义的步骤开始逐步执行。
chain.invoke({"input": "帮我写一篇关于AI的技术文章，100个字"})
```

### <font style="color:rgb(0, 0, 0);">输出转换</font>
<font style="color:rgb(0, 0, 0);">LLM的输出通常是一条消息，为了更方便处理结果，可以将消息转换为字符串。下面展示如何将LLM的输出消息转换为字符串：</font>

```python
from langchain_core.output_parsers import StrOutputParser

# 创建一个字符串输出解析器
output_parser = StrOutputParser()

# 将输出解析器添加到LLM链中，跟前面的例子，区别就是工作流编排，最后一步将llm模型输出的结果传递给output_parser进行格式转换
chain = prompt | llm | output_parser

# 调用LLM链并提出问题
chain.invoke({"input": "帮我写一篇langchain的技术文章，100个字"})
```

<font style="color:rgb(0, 0, 0);">以上是关于LLM链的介绍，希望能帮助您更好地理解如何安装LangChain并构建不同类型的链。</font>

